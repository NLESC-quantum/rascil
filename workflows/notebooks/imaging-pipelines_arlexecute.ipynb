{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline processing using arlexecute workflows.\n",
    "\n",
    "This notebook demonstrates the continuum imaging and ICAL pipelines. These are based on ARL functions wrapped up as SDP workflows using the arlexecute class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:36.390402Z",
     "start_time": "2018-11-27T10:28:34.467346Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join('..', '..'))\n",
    "\n",
    "from data_models.parameters import arl_path\n",
    "\n",
    "results_dir = arl_path('test_results')\n",
    "\n",
    "from matplotlib import pylab\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "pylab.rcParams['image.cmap'] = 'rainbow'\n",
    "\n",
    "import numpy\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data_models.polarisation import PolarisationFrame\n",
    "\n",
    "from wrappers.serial.calibration.calibration import solve_gaintable\n",
    "from wrappers.serial.calibration.operations import apply_gaintable\n",
    "from wrappers.serial.calibration.calibration_control import create_calibration_controls\n",
    "from wrappers.serial.visibility.base import create_blockvisibility\n",
    "from wrappers.serial.skycomponent.operations import create_skycomponent\n",
    "from wrappers.serial.image.deconvolution import deconvolve_cube\n",
    "from wrappers.serial.image.operations import show_image, export_image_to_fits, qa_image\n",
    "from wrappers.serial.visibility.iterators import vis_timeslice_iter\n",
    "from wrappers.serial.simulation.testing_support import create_named_configuration, create_low_test_image_from_gleam\n",
    "from wrappers.serial.imaging.base import predict_2d, create_image_from_visibility, advise_wide_field\n",
    "\n",
    "from workflows.arlexecute.imaging.imaging_arlexecute import invert_list_arlexecute_workflow, \\\n",
    "    predict_list_arlexecute_workflow, deconvolve_list_arlexecute_workflow\n",
    "from workflows.arlexecute.simulation.simulation_arlexecute import simulate_list_arlexecute_workflow, \\\n",
    "    corrupt_list_arlexecute_workflow\n",
    "from workflows.arlexecute.pipelines.pipeline_arlexecute import continuum_imaging_list_arlexecute_workflow, \\\n",
    "    ical_list_arlexecute_workflow\n",
    "\n",
    "from wrappers.arlexecute.execution_support.arlexecute import arlexecute\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "import logging\n",
    "\n",
    "def init_logging():\n",
    "    log = logging.getLogger()\n",
    "    logging.basicConfig(filename='%s/imaging-pipeline.log' % results_dir,\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "logging.info(\"Starting imaging-pipeline\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:40.240006Z",
     "start_time": "2018-11-27T10:28:37.150127Z"
    }
   },
   "outputs": [],
   "source": [
    "arlexecute.set_client(use_dask=True)\n",
    "arlexecute.run(init_logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:40.246425Z",
     "start_time": "2018-11-27T10:28:40.242389Z"
    }
   },
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "pylab.rcParams['image.cmap'] = 'Greys'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a graph to make the visibility. The parameter rmax determines the distance of the furthest antenna/stations used. All over parameters are determined from this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:42.018595Z",
     "start_time": "2018-11-27T10:28:40.248975Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nfreqwin=7\n",
    "ntimes=5\n",
    "rmax=300.0\n",
    "frequency=numpy.linspace(0.9e8,1.1e8,nfreqwin)\n",
    "channel_bandwidth=numpy.array(nfreqwin*[frequency[1]-frequency[0]])\n",
    "times = numpy.linspace(-numpy.pi/3.0, numpy.pi/3.0, ntimes)\n",
    "phasecentre=SkyCoord(ra=+30.0 * u.deg, dec=-60.0 * u.deg, frame='icrs', equinox='J2000')\n",
    "\n",
    "vis_list=simulate_list_arlexecute_workflow('LOWBD2',\n",
    "                                         frequency=frequency, \n",
    "                                         channel_bandwidth=channel_bandwidth,\n",
    "                                         times=times,\n",
    "                                         phasecentre=phasecentre,\n",
    "                                         order='frequency',\n",
    "                                        rmax=rmax, format='vis')\n",
    "print('%d elements in vis_list' % len(vis_list))\n",
    "log.info('About to make visibility')\n",
    "vis_list = arlexecute.compute(vis_list, sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:45.284904Z",
     "start_time": "2018-11-27T10:28:45.269275Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wprojection_planes=1\n",
    "advice_low=advise_wide_field(vis_list[0], guard_band_image=8.0, delA=0.02,\n",
    "                             wprojection_planes=wprojection_planes)\n",
    "\n",
    "advice_high=advise_wide_field(vis_list[-1], guard_band_image=8.0, delA=0.02,\n",
    "                              wprojection_planes=wprojection_planes)\n",
    "\n",
    "vis_slices = advice_low['vis_slices']\n",
    "npixel=advice_high['npixels2']\n",
    "cellsize=min(advice_low['cellsize'], advice_high['cellsize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a graph to fill with a model drawn from GLEAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:57.637288Z",
     "start_time": "2018-11-27T10:28:51.242572Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gleam_model = [arlexecute.execute(create_low_test_image_from_gleam)(npixel=npixel,\n",
    "                                                               frequency=[frequency[f]],\n",
    "                                                               channel_bandwidth=[channel_bandwidth[f]],\n",
    "                                                               cellsize=cellsize,\n",
    "                                                               phasecentre=phasecentre,\n",
    "                                                               polarisation_frame=PolarisationFrame(\"stokesI\"),\n",
    "                                                               flux_limit=1.0,\n",
    "                                                               applybeam=True)\n",
    "                     for f, freq in enumerate(frequency)]\n",
    "log.info('About to make GLEAM model')\n",
    "gleam_model = arlexecute.compute(gleam_model, sync=True)\n",
    "future_gleam_model = arlexecute.scatter(gleam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:29:11.651706Z",
     "start_time": "2018-11-27T10:28:57.644128Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log.info('About to run predict to get predicted visibility')\n",
    "future_vis_graph = arlexecute.scatter(vis_list)\n",
    "predicted_vislist = predict_list_arlexecute_workflow(future_vis_graph, gleam_model,  \n",
    "                                                context='wstack', vis_slices=vis_slices)\n",
    "predicted_vislist = arlexecute.compute(predicted_vislist, sync=True)\n",
    "corrupted_vislist = corrupt_list_arlexecute_workflow(predicted_vislist, phase_error=1.0)\n",
    "log.info('About to run corrupt to get corrupted visibility')\n",
    "#corrupted_vislist =  arlexecute.compute(corrupted_vislist, sync=True)\n",
    "future_predicted_vislist=arlexecute.scatter(predicted_vislist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the LSM. This is currently blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:29:11.661389Z",
     "start_time": "2018-11-27T10:29:11.654337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_list = [arlexecute.execute(create_image_from_visibility)(vis_list[f],\n",
    "                                                     npixel=npixel,\n",
    "                                                     frequency=[frequency[f]],\n",
    "                                                     channel_bandwidth=[channel_bandwidth[f]],\n",
    "                                                     cellsize=cellsize,\n",
    "                                                     phasecentre=phasecentre,\n",
    "                                                     polarisation_frame=PolarisationFrame(\"stokesI\"))\n",
    "               for f, freq in enumerate(frequency)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:29:11.759652Z",
     "start_time": "2018-11-27T10:29:11.664698Z"
    }
   },
   "outputs": [],
   "source": [
    "dirty_list = invert_list_arlexecute_workflow(future_predicted_vislist, model_list, \n",
    "                                  context='wstack',\n",
    "                                  vis_slices=vis_slices, dopsf=False)\n",
    "psf_list = invert_list_arlexecute_workflow(future_predicted_vislist, model_list, \n",
    "                                context='wstack',\n",
    "                                vis_slices=vis_slices, dopsf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and execute graphs to make the dirty image and PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:29:34.428399Z",
     "start_time": "2018-11-27T10:29:11.762072Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log.info('About to run invert to get dirty image')\n",
    "\n",
    "dirty_list =  arlexecute.compute(dirty_list, sync=True)\n",
    "dirty = dirty_list[0][0]\n",
    "show_image(dirty, cm='Greys', vmax=1.0, vmin=-0.1)\n",
    "plt.show()\n",
    "\n",
    "log.info('About to run invert to get PSF')\n",
    "\n",
    "\n",
    "psf_list =  arlexecute.compute(psf_list, sync=True)\n",
    "psf = psf_list[0][0]\n",
    "show_image(psf, cm='Greys', vmax=0.1, vmin=-0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deconvolve using msclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:29:37.089001Z",
     "start_time": "2018-11-27T10:29:34.430444Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log.info('About to run deconvolve')\n",
    "\n",
    "deconvolve_list = \\\n",
    "    deconvolve_list_arlexecute_workflow(dirty_list, psf_list, model_imagelist=model_list, \n",
    "                            deconvolve_facets=8, deconvolve_overlap=16, deconvolve_taper='tukey',\n",
    "                            scales=[0, 3, 10],\n",
    "                            algorithm='msclean', niter=1000, \n",
    "                            fractional_threshold=0.1,\n",
    "                            threshold=0.1, gain=0.1, psf_support=64)\n",
    "    \n",
    "deconvolved = arlexecute.compute(deconvolve_list, sync=True)\n",
    "show_image(deconvolved[0], cm='Greys', vmax=0.1, vmin=-0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:29:44.930625Z",
     "start_time": "2018-11-27T10:29:37.091329Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "continuum_imaging_list = \\\n",
    "    continuum_imaging_list_arlexecute_workflow(future_predicted_vislist, \n",
    "                                            model_imagelist=model_list, \n",
    "                                            context='wstack', vis_slices=vis_slices, \n",
    "                                            scales=[0, 3, 10], algorithm='mmclean', \n",
    "                                            nmoment=3, niter=1000, \n",
    "                                            fractional_threshold=0.1,\n",
    "                                            threshold=0.1, nmajor=5, gain=0.25,\n",
    "                                            deconvolve_facets = 8, deconvolve_overlap=16, \n",
    "                                            deconvolve_taper='tukey', psf_support=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:33:00.940388Z",
     "start_time": "2018-11-27T10:29:44.933904Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log.info('About to run continuum imaging')\n",
    "\n",
    "result=arlexecute.compute(continuum_imaging_list, sync=True)\n",
    "deconvolved = result[0][0]\n",
    "residual = result[1][0]\n",
    "restored = result[2][0]\n",
    "\n",
    "f=show_image(deconvolved, title='Clean image - no selfcal', cm='Greys', \n",
    "             vmax=0.1, vmin=-0.01)\n",
    "print(qa_image(deconvolved, context='Clean image - no selfcal'))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f=show_image(restored, title='Restored clean image - no selfcal', \n",
    "             cm='Greys', vmax=1.0, vmin=-0.1)\n",
    "print(qa_image(restored, context='Restored clean image - no selfcal'))\n",
    "plt.show()\n",
    "export_image_to_fits(restored, '%s/imaging-dask_continuum_imaging_restored.fits' \n",
    "                     %(results_dir))\n",
    "\n",
    "f=show_image(residual[0], title='Residual clean image - no selfcal', cm='Greys', \n",
    "             vmax=0.1, vmin=-0.01)\n",
    "print(qa_image(residual[0], context='Residual clean image - no selfcal'))\n",
    "plt.show()\n",
    "export_image_to_fits(residual[0], '%s/imaging-dask_continuum_imaging_residual.fits' \n",
    "                     %(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:33:05.468566Z",
     "start_time": "2018-11-27T10:33:00.942877Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for chan in range(nfreqwin):\n",
    "    residual = result[1][chan]\n",
    "    show_image(residual[0], title='Channel %d' % chan, cm='Greys', \n",
    "               vmax=0.1, vmin=-0.01)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
